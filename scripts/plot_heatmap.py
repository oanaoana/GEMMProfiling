#!/usr/bin/env python3
"""
Heatmap plotting script for per-tile reference analysis results.
Reads binary files generated by run_per_tile_reference_analysis() and creates heatmaps.
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors
import pandas as pd
import struct
import glob
import os
import argparse
from pathlib import Path

# ===== CONFIGURATION OPTIONS =====
# Choose which statistics to plot (set to True/False)
PLOT_MATRIX = False          # Plot the full matrix heatmap
PLOT_TILE_MEANS = True      # Plot per-tile mean statistics
PLOT_TILE_STDS = True       # Plot per-tile standard deviation statistics
PLOT_TILE_MINS = False       # Plot per-tile minimum statistics
PLOT_TILE_MAXS = True       # Plot per-tile maximum statistics
PLOT_COMBINED_TILES = False # Plot all tile stats in one 2x2 figure (old behavior)

# Kernel filtering and comparison
FILTER_KERNELS = True                           # Enable/disable kernel filtering
ALLOWED_KERNELS = ["tiled", "tiled_pairwise"]   # Kernels to compare with consistent scaling
USE_CROSS_KERNEL_SCALING = True                 # Use consistent colorbar across kernels for each statistic

# Matrix type filtering (optional)
FILTER_MATRIX_TYPES = False              # Enable/disable matrix type filtering
ALLOWED_MATRIX_TYPES = ["uniform_positive"]  # List of matrix types to process

# Visual and output options
DEFAULT_COLORMAP = 'viridis'    # Default colormap for all plots
SHOW_TILE_GRID = True           # Show tile grid overlay on matrix plot
SAVE_HIGH_DPI = True            # Save plots at high DPI (300)

# File format options
SAVE_FORMAT = "png"            # Options: "png", "eps", "both"
PNG_DPI = 300                   # DPI for PNG files (only affects PNG)
EPS_DPI = 300                   # DPI for EPS files (only affects EPS)
# ===================================

# Configuration
OUTPUT_DIR = "plots"
DATA_DIR = "data"

# Font and style configuration
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.size'] = 12
TITLE_FONTSIZE = 14
AXIS_LABEL_FONTSIZE = 14
TICK_LABEL_FONTSIZE = 14
COLORBAR_FONTSIZE = 14

def compute_global_color_scale(matrix_data, tile_stats, log_scale=False):
    """
    Compute consistent color scale across matrix data and all tile statistics.
    """
    # Collect all data
    all_data = []

    # Add matrix data
    if PLOT_MATRIX:
        all_data.append(matrix_data.flatten())

    # Add selected tile statistics
    if PLOT_TILE_MEANS and 'means' in tile_stats:
        all_data.append(tile_stats['means'].flatten())
    if PLOT_TILE_STDS and 'stds' in tile_stats:
        all_data.append(tile_stats['stds'].flatten())
    if PLOT_TILE_MINS and 'mins' in tile_stats:
        all_data.append(tile_stats['mins'].flatten())
    if PLOT_TILE_MAXS and 'maxs' in tile_stats:
        all_data.append(tile_stats['maxs'].flatten())

    if not all_data:
        print("Warning: No data selected for plotting")
        return 0, 1, False

    # Combine all data
    combined_data = np.concatenate(all_data)

    if log_scale:
        # For log scale, only consider positive values
        positive_data = combined_data[combined_data > 0]
        if len(positive_data) == 0:
            print("Warning: No positive values found for log scale, using linear scale")
            vmin, vmax = np.min(combined_data), np.max(combined_data)
            use_log = False
        else:
            vmin, vmax = np.min(positive_data), np.max(positive_data)
            use_log = True
            print(f"Global log color scale: {vmin:.3e} to {vmax:.3e}")
    else:
        vmin, vmax = np.min(combined_data), np.max(combined_data)
        use_log = False
        print(f"Global linear color scale: {vmin:.3e} to {vmax:.3e}")

    return vmin, vmax, use_log

def read_binary_file(filepath):
    """
    Read simplified binary file, compute tile statistics, and get metadata from CSV.
    """
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"Binary file not found: {filepath}")

    with open(filepath, 'rb') as f:
        # Read header (6 integers)
        header_data = struct.unpack('iiiiii', f.read(6 * 4))
        n, sample_index, matrix_type_enum, kernel_type_enum, tile_size, num_tiles_per_dim = header_data
        total_tiles = num_tiles_per_dim * num_tiles_per_dim

        # Read the full matrix normalized errors (n*n doubles)
        total_elements = n * n
        matrix_bytes = f.read(total_elements * 8)  # 8 bytes per double

        if len(matrix_bytes) != total_elements * 8:
            raise ValueError(f"Expected {total_elements * 8} bytes for matrix, got {len(matrix_bytes)}")

        # Unpack matrix data as doubles
        matrix_data = struct.unpack(f'{total_elements}d', matrix_bytes)
        matrix_data = np.array(matrix_data).reshape(n, n)

    # Read metadata from CSV to get the actual string names
    metadata = read_metadata_csv(filepath)

    if metadata is not None and len(metadata) > 0:
        # Use the string names from CSV metadata (preferred method)
        matrix_type_name = metadata.iloc[0]['matrix_type']
        kernel_type_name = metadata.iloc[0]['kernel_type']
        print(f"Using names from CSV: kernel='{kernel_type_name}', matrix='{matrix_type_name}'")
    else:
        # Fallback: construct names from enum values (basic fallback)
        matrix_type_name = f"matrix_type_{matrix_type_enum}"
        kernel_type_name = f"kernel_type_{kernel_type_enum}"
        print(f"Warning: No CSV metadata found, using fallback names: kernel='{kernel_type_name}', matrix='{matrix_type_name}'")

    # Compute tile statistics in Python
    print(f"Computing tile statistics: {num_tiles_per_dim}×{num_tiles_per_dim} tiles of size {tile_size}×{tile_size}")

    tile_stats = compute_tile_statistics(matrix_data, tile_size)

    header = {
        'matrix_size': n,
        'sample_index': sample_index,
        'matrix_type': matrix_type_enum,  # Keep enum for compatibility if needed
        'kernel_type': kernel_type_enum,   # Keep enum for compatibility if needed
        'tile_size': tile_size,
        'num_tiles_per_dim': num_tiles_per_dim,
        'total_tiles': total_tiles,
        'matrix_type_name': matrix_type_name,    # Use string from CSV
        'kernel_type_name': kernel_type_name     # Use string from CSV
    }

    return {
        'header': header,
        'matrix_data': matrix_data,
        'tile_stats': tile_stats
    }

def read_metadata_csv(filepath):
    """Read the metadata CSV file if it exists."""
    csv_path = filepath.replace('.bin', '_info.csv')
    if os.path.exists(csv_path):
        try:
            return pd.read_csv(csv_path)
        except Exception as e:
            print(f"Warning: Could not read CSV metadata: {e}")
            return None
    else:
        print(f"Warning: CSV metadata file not found: {csv_path}")
        return None

def compute_tile_statistics(matrix_data, tile_size):
    """
    Compute per-tile statistics from the full error matrix.
    """
    n = matrix_data.shape[0]
    num_tiles_per_dim = (n + tile_size - 1) // tile_size

    # Initialize arrays for tile statistics
    tile_means = np.zeros((num_tiles_per_dim, num_tiles_per_dim))
    tile_stds = np.zeros((num_tiles_per_dim, num_tiles_per_dim))
    tile_mins = np.zeros((num_tiles_per_dim, num_tiles_per_dim))
    tile_maxs = np.zeros((num_tiles_per_dim, num_tiles_per_dim))  # Fixed typo here
    tile_sizes = np.zeros((num_tiles_per_dim, num_tiles_per_dim), dtype=int)

    for tile_row in range(num_tiles_per_dim):
        for tile_col in range(num_tiles_per_dim):
            # Determine tile boundaries
            row_start = tile_row * tile_size
            row_end = min(row_start + tile_size, n)
            col_start = tile_col * tile_size
            col_end = min(col_start + tile_size, n)

            # Extract tile data using numpy slicing (much faster than loops)
            tile_data = matrix_data[row_start:row_end, col_start:col_end]

            # Compute statistics using numpy (very fast)
            tile_means[tile_row, tile_col] = np.mean(tile_data)
            tile_stds[tile_row, tile_col] = np.std(tile_data)
            tile_mins[tile_row, tile_col] = np.min(tile_data)
            tile_maxs[tile_row, tile_col] = np.max(tile_data)
            tile_sizes[tile_row, tile_col] = tile_data.size

    return {
        'means': tile_means,
        'stds': tile_stds,
        'mins': tile_mins,
        'maxs': tile_maxs,
        'sizes': tile_sizes
    }

def compute_fixed_color_scale(matrix_data, tile_stats, log_scale=False):
    """
    Use fixed color scale with predefined min/max values.
    """
    if log_scale:
        vmin, vmax = FIXED_VMIN, FIXED_VMAX
        use_log = True
        print(f"Fixed log color scale: {vmin:.3e} to {vmax:.3e}")
    else:
        vmin, vmax = FIXED_VMIN, FIXED_VMAX
        use_log = False
        print(f"Fixed linear color scale: {vmin:.3e} to {vmax:.3e}")

    # Check if data exceeds fixed scale and warn user
    all_data = []
    if PLOT_MATRIX:
        all_data.append(matrix_data.flatten())
    if PLOT_TILE_MEANS and 'means' in tile_stats:
        all_data.append(tile_stats['means'].flatten())
    if PLOT_TILE_STDS and 'stds' in tile_stats:
        all_data.append(tile_stats['stds'].flatten())
    if PLOT_TILE_MINS and 'mins' in tile_stats:
        all_data.append(tile_stats['mins'].flatten())
    if PLOT_TILE_MAXS and 'maxs' in tile_stats:
        all_data.append(tile_stats['maxs'].flatten())

    if all_data:
        combined_data = np.concatenate(all_data)
        data_min, data_max = np.min(combined_data), np.max(combined_data)

        if data_min < vmin:
            print(f"Warning: Data minimum ({data_min:.3e}) is below fixed scale minimum ({vmin:.3e})")
        if data_max > vmax:
            print(f"Warning: Data maximum ({data_max:.3e}) exceeds fixed scale maximum ({vmax:.3e})")

        print(f"Actual data range: {data_min:.3e} to {data_max:.3e}")

    return vmin, vmax, use_log

def compute_cross_kernel_color_scales(all_results, log_scale=False):
    """
    Compute consistent color scales across kernels for each statistic type.
    Returns a dictionary with vmin/vmax for each plot type.
    """
    scales = {}

    print(f"\n=== Computing Cross-Kernel Color Scales ===")
    print(f"Kernels: {[result['header']['kernel_type_name'] for result in all_results]}")

    # Collect data for each plot type
    plot_types = []
    if PLOT_MATRIX:
        plot_types.append(('matrix', 'Matrix Data'))
    if PLOT_TILE_MEANS:
        plot_types.append(('tile_means', 'Tile Means'))
    if PLOT_TILE_STDS:
        plot_types.append(('tile_stds', 'Tile Std Devs'))
    if PLOT_TILE_MINS:
        plot_types.append(('tile_mins', 'Tile Mins'))
    if PLOT_TILE_MAXS:
        plot_types.append(('tile_maxs', 'Tile Maxs'))

    for plot_type, plot_name in plot_types:
        combined_data = []

        # Collect data from all kernels for this plot type
        for result in all_results:
            if plot_type == 'matrix':
                combined_data.append(result['matrix_data'].flatten())
            elif plot_type == 'tile_means':
                combined_data.append(result['tile_stats']['means'].flatten())
            elif plot_type == 'tile_stds':
                combined_data.append(result['tile_stats']['stds'].flatten())
            elif plot_type == 'tile_mins':
                combined_data.append(result['tile_stats']['mins'].flatten())
            elif plot_type == 'tile_maxs':
                combined_data.append(result['tile_stats']['maxs'].flatten())

        if combined_data:
            # Combine data from all kernels
            all_data = np.concatenate(combined_data)

            if log_scale:
                # For log scale, only consider positive values
                positive_data = all_data[all_data > 0]
                if len(positive_data) == 0:
                    print(f"Warning: No positive values found for {plot_name} log scale")
                    vmin, vmax = np.min(all_data), np.max(all_data)
                    use_log = False
                else:
                    vmin, vmax = np.min(positive_data), np.max(positive_data)
                    use_log = True
            else:
                vmin, vmax = np.min(all_data), np.max(all_data)
                use_log = log_scale

            scales[plot_type] = {
                'vmin': vmin,
                'vmax': vmax,
                'use_log': use_log
            }

            print(f"{plot_name}: {vmin:.3e} to {vmax:.3e} {'(log)' if use_log else '(linear)'}")

    print("=" * 50)
    return scales

def should_process_file(filepath):
    """
    Check if a file should be processed based on kernel and matrix type filters.
    """
    metadata = read_metadata_csv(filepath)

    if metadata is None or len(metadata) == 0:
        print(f"Warning: No metadata found for {filepath}, skipping filtering")
        return True

    kernel_name = metadata.iloc[0]['kernel_type']
    matrix_name = metadata.iloc[0]['matrix_type']

    # Check kernel filter
    if FILTER_KERNELS and ALLOWED_KERNELS:
        if kernel_name not in ALLOWED_KERNELS:
            return False

    # Check matrix type filter
    if FILTER_MATRIX_TYPES and ALLOWED_MATRIX_TYPES:
        if matrix_name not in ALLOWED_MATRIX_TYPES:
            return False

    return True

def get_save_paths(base_path, format_option):
    """
    Generate save paths based on format option.
    Returns list of (path, format) tuples.
    """
    paths = []

    if format_option.lower() == "png":
        paths.append((f"{base_path}.png", "png"))
    elif format_option.lower() == "eps":
        paths.append((f"{base_path}.eps", "eps"))
    elif format_option.lower() == "both":
        paths.append((f"{base_path}.png", "png"))
        paths.append((f"{base_path}.eps", "eps"))
    else:
        print(f"Warning: Unknown format '{format_option}', defaulting to PNG")
        paths.append((f"{base_path}.png", "png"))

    return paths

def save_figure(fig, base_path, format_option=SAVE_FORMAT):
    """
    Save figure in specified format(s).
    """
    save_paths = get_save_paths(base_path, format_option)

    for save_path, fmt in save_paths:
        # Create directory if it doesn't exist
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

        # Set DPI based on format
        if fmt == "png":
            dpi = PNG_DPI if SAVE_HIGH_DPI else 150
        elif fmt == "eps":
            dpi = EPS_DPI if SAVE_HIGH_DPI else 150
        else:
            dpi = 300

        # Save with appropriate settings
        if fmt == "eps":
            # EPS-specific settings
            fig.savefig(save_path, format='eps', dpi=dpi, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
        else:
            # PNG and other formats
            fig.savefig(save_path, format=fmt, dpi=dpi, bbox_inches='tight')

        print(f"Plot saved to: {save_path}")

def save_plot_metadata(save_path, stat_name, header, actual_min, actual_max, actual_mean,
                      vmin, vmax, use_log, kernel_type):
    """
    Save plot metadata to a corresponding .txt file.
    """
    if not save_path:
        return

    # Create .txt filename by removing any existing extension and adding .txt
    base_path = save_path
    # Remove common extensions
    for ext in ['.png', '.eps', '.pdf', '.svg']:
        if base_path.endswith(ext):
            base_path = base_path[:-len(ext)]
            break

    txt_path = f"{base_path}.txt"

    try:
        with open(txt_path, 'w') as f:
            f.write("=== PLOT METADATA ===\n")
            f.write(f"Statistic: {stat_name}\n")
            f.write(f"Kernel: {kernel_type}\n")
            f.write(f"Matrix Type: {header['matrix_type_name']}\n")
            f.write(f"Matrix Size: {header['matrix_size']}x{header['matrix_size']}\n")
            f.write(f"Sample Index: {header['sample_index']}\n")
            f.write(f"Tile Size: {header['tile_size']}x{header['tile_size']}\n")
            f.write(f"Tiles per Dimension: {header['num_tiles_per_dim']}\n")
            f.write(f"Total Tiles: {header['total_tiles']}\n")
            f.write("\n=== ACTUAL DATA RANGE ===\n")
            f.write(f"Minimum: {actual_min:.6e}\n")
            f.write(f"Maximum: {actual_max:.6e}\n")
            f.write(f"Mean: {actual_mean:.6e}\n")
            f.write("\n=== CROSS-KERNEL COLOR SCALE ===\n")
            f.write(f"Scale Minimum: {vmin:.6e}\n")
            f.write(f"Scale Maximum: {vmax:.6e}\n")
            f.write(f"Scale Type: {'Logarithmic' if use_log else 'Linear'}\n")
            f.write("\n=== ADDITIONAL INFO ===\n")
            f.write(f"Data clipped to scale range: {actual_min < vmin or actual_max > vmax}\n")
            if actual_min < vmin:
                f.write(f"Data minimum below scale minimum by: {vmin - actual_min:.6e}\n")
            if actual_max > vmax:
                f.write(f"Data maximum above scale maximum by: {actual_max - vmax:.6e}\n")

        print(f"Metadata saved to: {txt_path}")

    except Exception as e:
        print(f"Error saving metadata to {txt_path}: {e}")

def create_matrix_heatmap(data, header, metadata=None, colormap=DEFAULT_COLORMAP,
                         vmin=None, vmax=None, use_log=False, save_path=None, format_option=SAVE_FORMAT):
    """
    Create a heatmap of the full matrix with consistent color scaling.
    """
    n = header['matrix_size']
    tile_size = header['tile_size']
    matrix_type = header['matrix_type_name']
    kernel_type = header['kernel_type_name']
    sample_idx = header['sample_index']

    fig, ax = plt.subplots(figsize=(12, 10))

    # Apply color scaling
    if use_log:
        data_plot = np.where(data > 0, data, np.nan)
        data_plot = np.clip(data_plot, vmin, vmax)
        norm = colors.LogNorm(vmin=vmin, vmax=vmax)
        scale_label = f'cross-kernel log scale: {vmin:.0e}-{vmax:.0e}'
    else:
        data_plot = np.clip(data, vmin, vmax)
        norm = colors.Normalize(vmin=vmin, vmax=vmax)
        scale_label = f'cross-kernel scale: {vmin:.0e}-{vmax:.0e}'

    im = ax.imshow(data_plot, cmap=colormap, norm=norm, aspect='equal', origin='upper')

    # Add tile grid overlay
    if SHOW_TILE_GRID and tile_size > 1:
        for x in range(tile_size, n, tile_size):
            ax.axvline(x - 0.5, color='white', linewidth=0.5, alpha=0.7)
        for y in range(tile_size, n, tile_size):
            ax.axhline(y - 0.5, color='white', linewidth=0.5, alpha=0.7)

    # Add colorbar (no label)
    cbar = plt.colorbar(im, ax=ax, shrink=0.8)
    cbar.ax.tick_params(labelsize=TICK_LABEL_FONTSIZE)

    # Set labels and title
    ax.set_xlabel('Column Index', fontsize=AXIS_LABEL_FONTSIZE)
    ax.set_ylabel('Row Index', fontsize=AXIS_LABEL_FONTSIZE)

    # Clean title format
    if kernel_type == 'tiled_pairwise':
        title = 'Pairwise Summation: Matrix Error'
    elif kernel_type == 'tiled':
        title = 'Flat Summation: Matrix Error'
    else:
        title = f'{kernel_type}: Matrix Error'

    ax.set_title(title, fontsize=TITLE_FONTSIZE, pad=20)
    ax.tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)
    plt.tight_layout()

    # Save metadata to .txt file
    if save_path:
        actual_min, actual_max, actual_mean = np.min(data), np.max(data), np.mean(data)
        save_plot_metadata(save_path, 'matrix', header, actual_min, actual_max, actual_mean,
                          vmin, vmax, use_log, kernel_type)

    if save_path:
        save_figure(fig, save_path, format_option)
    else:
        plt.show()

    plt.close()

def create_individual_tile_stat_heatmap(data, stat_name, header, metadata=None, colormap=DEFAULT_COLORMAP,
                                       vmin=None, vmax=None, use_log=False, save_path=None, format_option=SAVE_FORMAT):
    """
    Create an individual heatmap for a single tile statistic.
    """
    matrix_type = header['matrix_type_name']
    kernel_type = header['kernel_type_name']
    sample_idx = header['sample_index']
    tile_size = header['tile_size']
    n = header['matrix_size']

    fig, ax = plt.subplots(figsize=(10, 8))

    # Apply color scaling
    if use_log:
        data_plot = np.where(data > 0, data, np.nan)
        data_plot = np.clip(data_plot, vmin, vmax)
        norm = colors.LogNorm(vmin=vmin, vmax=vmax)
    else:
        data_plot = np.clip(data, vmin, vmax)
        norm = colors.Normalize(vmin=vmin, vmax=vmax)

    im = ax.imshow(data_plot, cmap=colormap, norm=norm, aspect='equal', origin='upper')

    # Add colorbar (no label)
    cbar = plt.colorbar(im, ax=ax, shrink=0.8)
    cbar.ax.tick_params(labelsize=TICK_LABEL_FONTSIZE)

    # Set labels and title
    ax.set_xlabel('Tile Column', fontsize=AXIS_LABEL_FONTSIZE)
    ax.set_ylabel('Tile Row', fontsize=AXIS_LABEL_FONTSIZE)

    # Custom title based on kernel type and statistic - CLEAN VERSION
    if stat_name.lower() == 'maxs' or stat_name.lower() == 'max':
        if kernel_type == 'tiled_pairwise':
            title = 'Pairwise Summation: Max Error per Tile'
        elif kernel_type == 'tiled':
            title = 'Flat Summation: Max Error per Tile'
        else:
            # Fallback for other kernels
            title = f'{kernel_type}: Max Error per Tile'
    else:
        # For other statistics, use kernel-specific naming
        if kernel_type == 'tiled_pairwise':
            title = f'Pairwise Summation: {stat_name.capitalize()} Error per Tile'
        elif kernel_type == 'tiled':
            title = f'Flat Summation: {stat_name.capitalize()} Error per Tile'
        else:
            # Fallback for other kernels
            title = f'{kernel_type}: {stat_name.capitalize()} Error per Tile'

    ax.set_title(title, fontsize=TITLE_FONTSIZE, pad=20)
    ax.tick_params(labelsize=TICK_LABEL_FONTSIZE)

    plt.tight_layout()

    # Save metadata to .txt file
    if save_path:
        actual_min, actual_max, actual_mean = np.min(data), np.max(data), np.mean(data)
        save_plot_metadata(save_path, stat_name, header, actual_min, actual_max, actual_mean,
                          vmin, vmax, use_log, kernel_type)

    if save_path:
        save_figure(fig, save_path, format_option)
    else:
        plt.show()

    plt.close()

def create_combined_tile_stats_heatmap(tile_stats, header, metadata=None, colormap=DEFAULT_COLORMAP,
                                      vmin=None, vmax=None, use_log=False, save_path=None, format_option=SAVE_FORMAT):
    """
    Create the old-style 2x2 combined tile statistics heatmap.
    """
    matrix_type = header['matrix_type_name']
    kernel_type = header['kernel_type_name']
    sample_idx = header['sample_index']
    tile_size = header['tile_size']
    n = header['matrix_size']

    # Create 2x2 subplot for the four statistics
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))

    # Clean title for combined plot
    if kernel_type == 'tiled_pairwise':
        title_text = 'Pairwise Summation: Per-Tile Statistics'
    elif kernel_type == 'tiled':
        title_text = 'Flat Summation: Per-Tile Statistics'
    else:
        title_text = f'{kernel_type}: Per-Tile Statistics'

    fig.suptitle(title_text, fontsize=TITLE_FONTSIZE)

    stats_data = [
        (tile_stats['means'], 'Mean Error per Tile', 'means'),
        (tile_stats['stds'], 'Std Dev per Tile', 'stds'),
        (tile_stats['mins'], 'Min Error per Tile', 'mins'),
        (tile_stats['maxs'], 'Max Error per Tile', 'maxs')
    ]

    positions = [(0, 0), (0, 1), (1, 0), (1, 1)]

    for (data, title, label), (row, col) in zip(stats_data, positions):
        ax = axes[row, col]

        # Use cross-kernel color scaling for all subplots
        if use_log and vmin is not None and vmax is not None:
            data_plot = np.where(data > 0, data, np.nan)
            data_plot = np.clip(data_plot, vmin, vmax)
            norm = colors.LogNorm(vmin=vmin, vmax=vmax)
        elif vmin is not None and vmax is not None:
            data_plot = np.clip(data, vmin, vmax)
            norm = colors.Normalize(vmin=vmin, vmax=vmax)
        else:
            # Individual scaling per subplot (fallback)
            if use_log and np.any(data > 0):
                data_plot = np.where(data > 0, data, np.nan)
                norm = colors.LogNorm()
            else:
                data_plot = data
                norm = colors.Normalize()

        im = ax.imshow(data_plot, cmap=colormap, norm=norm, aspect='equal', origin='upper')

        # Add colorbar for each subplot (no label)
        cbar = plt.colorbar(im, ax=ax, shrink=0.8)
        cbar.ax.tick_params(labelsize=TICK_LABEL_FONTSIZE-2)

        ax.set_title(title, fontsize=TITLE_FONTSIZE-2)
        ax.set_xlabel('Tile Column', fontsize=AXIS_LABEL_FONTSIZE-2)
        ax.set_ylabel('Tile Row', fontsize=AXIS_LABEL_FONTSIZE-2)
        ax.tick_params(labelsize=TICK_LABEL_FONTSIZE-2)

    plt.tight_layout()

    # Save metadata to .txt file for combined plot
    if save_path:
        # For combined plot, save metadata for all statistics
        # Remove any existing extension and add .txt
        base_path = save_path
        for ext in ['.png', '.eps', '.pdf', '.svg']:
            if base_path.endswith(ext):
                base_path = base_path[:-len(ext)]
                break

        combined_metadata_path = f"{base_path}.txt"

        try:
            with open(combined_metadata_path, 'w') as f:
                f.write("=== COMBINED PLOT METADATA ===\n")
                f.write(f"Kernel: {kernel_type}\n")
                f.write(f"Matrix Type: {matrix_type}\n")
                f.write(f"Matrix Size: {n}x{n}\n")
                f.write(f"Sample Index: {sample_idx}\n")
                f.write(f"Tile Size: {tile_size}x{tile_size}\n")
                f.write(f"Cross-Kernel Scale: {vmin:.6e} to {vmax:.6e} ({'log' if use_log else 'linear'})\n")
                f.write("\n")

                for (data, title, label), (row, col) in zip(stats_data, positions):
                    actual_min, actual_max, actual_mean = np.min(data), np.max(data), np.mean(data)
                    f.write(f"=== {label.upper()} STATISTICS ===\n")
                    f.write(f"Minimum: {actual_min:.6e}\n")
                    f.write(f"Maximum: {actual_max:.6e}\n")
                    f.write(f"Mean: {actual_mean:.6e}\n")
                    f.write("\n")

            print(f"Combined metadata saved to: {combined_metadata_path}")
        except Exception as e:
            print(f"Error saving combined metadata: {e}")

    if save_path:
        save_figure(fig, save_path, format_option)
    else:
        plt.show()

    plt.close()

def create_all_plots_with_cross_kernel_scaling(all_results, metadata_list=None, colormap=DEFAULT_COLORMAP,
                                             log_scale=False, save_path_prefixes=None, format_option=SAVE_FORMAT):
    """
    Create all plots with consistent scaling across kernels for each statistic type.
    """
    if not all_results:
        print("No results to plot")
        return

    # Compute cross-kernel color scales
    scales = compute_cross_kernel_color_scales(all_results, log_scale)

    # Create plots for each kernel using consistent scales
    for i, result in enumerate(all_results):
        matrix_data = result['matrix_data']
        tile_stats = result['tile_stats']
        header = result['header']
        metadata = metadata_list[i] if metadata_list and i < len(metadata_list) else None
        save_path_prefix = save_path_prefixes[i] if save_path_prefixes and i < len(save_path_prefixes) else None

        print(f"\nCreating plots for kernel: {header['kernel_type_name']}")

        # Create matrix heatmap if enabled
        if PLOT_MATRIX and 'matrix' in scales:
            matrix_save_path = f"{save_path_prefix}_matrix" if save_path_prefix else None
            create_matrix_heatmap(matrix_data, header, metadata, colormap=colormap,
                                 vmin=scales['matrix']['vmin'], vmax=scales['matrix']['vmax'],
                                 use_log=scales['matrix']['use_log'], save_path=matrix_save_path,
                                 format_option=format_option)

        # Create individual tile statistics plots
        tile_stats_to_plot = []
        if PLOT_TILE_MEANS and 'tile_means' in scales:
            tile_stats_to_plot.append(('means', 'means', 'tile_means'))
        if PLOT_TILE_STDS and 'tile_stds' in scales:
            tile_stats_to_plot.append(('stds', 'stds', 'tile_stds'))
        if PLOT_TILE_MINS and 'tile_mins' in scales:
            tile_stats_to_plot.append(('mins', 'mins', 'tile_mins'))
        if PLOT_TILE_MAXS and 'tile_maxs' in scales:
            tile_stats_to_plot.append(('maxs', 'maxs', 'tile_maxs'))

        for stat_key, stat_name, scale_key in tile_stats_to_plot:
            if stat_key in tile_stats:
                individual_save_path = f"{save_path_prefix}_tile_{stat_name}" if save_path_prefix else None

                create_individual_tile_stat_heatmap(tile_stats[stat_key], stat_name, header, metadata,
                                                  colormap=colormap,
                                                  vmin=scales[scale_key]['vmin'],
                                                  vmax=scales[scale_key]['vmax'],
                                                  use_log=scales[scale_key]['use_log'],
                                                  save_path=individual_save_path,
                                                  format_option=format_option)

        # Create combined tile statistics plot if enabled
        if PLOT_COMBINED_TILES:
            combined_save_path = f"{save_path_prefix}_tile_combined" if save_path_prefix else None

            # For combined plots, use the first available scale
            if scales:
                first_scale_key = list(scales.keys())[0]
                vmin = scales[first_scale_key]['vmin']
                vmax = scales[first_scale_key]['vmax']
                use_log = scales[first_scale_key]['use_log']
            else:
                vmin = vmax = None
                use_log = log_scale

            create_combined_tile_stats_heatmap(tile_stats, header, metadata,
                                              colormap=colormap, vmin=vmin, vmax=vmax, use_log=use_log,
                                              save_path=combined_save_path, format_option=format_option)

def print_tile_statistics_summary(tile_stats, header):
    """Print a summary of tile statistics."""
    print(f"\n=== Tile Statistics Summary ===")
    print(f"Tile grid: {header['num_tiles_per_dim']}×{header['num_tiles_per_dim']} tiles")
    print(f"Tile size: {header['tile_size']}×{header['tile_size']} elements")
    print(f"Total tiles: {header['total_tiles']}")

    for stat_name, data in tile_stats.items():
        if stat_name == 'sizes':
            continue
        print(f"\n{stat_name.upper()} per tile:")
        print(f"  Min: {np.min(data):.6e}")
        print(f"  Max: {np.max(data):.6e}")
        print(f"  Mean: {np.mean(data):.6e}")
        print(f"  Std: {np.std(data):.6e}")

def main():
    # Move global declaration to the top, before any usage
    global SHOW_TILE_GRID, SAVE_FORMAT, PNG_DPI, EPS_DPI

    parser = argparse.ArgumentParser(description='Plot heatmaps from per-tile reference analysis')
    parser.add_argument('--data-dir', default=DATA_DIR, help='Directory containing binary files')
    parser.add_argument('--output-dir', default=OUTPUT_DIR, help='Directory to save plots')
    parser.add_argument('--pattern', default='*_per_tile_*.bin', help='File pattern to match')
    parser.add_argument('--colormap', default=DEFAULT_COLORMAP, help='Matplotlib colormap name')
    parser.add_argument('--log-scale', action='store_true', help='Use logarithmic color scale')
    parser.add_argument('--file', help='Plot specific binary file')
    parser.add_argument('--no-grid', action='store_true', help='Hide tile grid overlay on matrix')

    # Add file format options
    parser.add_argument('--format', choices=['png', 'eps', 'both'], default=SAVE_FORMAT,
                       help='Output file format (default: %(default)s)')
    parser.add_argument('--png-dpi', type=int, default=PNG_DPI,
                       help='DPI for PNG files (default: %(default)d)')
    parser.add_argument('--eps-dpi', type=int, default=EPS_DPI,
                       help='DPI for EPS files (default: %(default)d)')

    args = parser.parse_args()

    # Now override configuration with command line arguments
    SHOW_TILE_GRID = not args.no_grid
    SAVE_FORMAT = args.format
    PNG_DPI = args.png_dpi
    EPS_DPI = args.eps_dpi

    os.makedirs(args.output_dir, exist_ok=True)

    print(f"Output format: {SAVE_FORMAT.upper()}")
    if SAVE_FORMAT in ["png", "both"]:
        print(f"PNG DPI: {PNG_DPI}")
    if SAVE_FORMAT in ["eps", "both"]:
        print(f"EPS DPI: {EPS_DPI}")

    if args.file:
        print(f"Single file mode not supported for cross-kernel scaling")
        print(f"Use batch processing to compare kernels")
        return
    else:
        # Find and filter binary files
        pattern = os.path.join(args.data_dir, args.pattern)
        binary_files = glob.glob(pattern)

        if not binary_files:
            print(f"No files found matching pattern: {pattern}")
            return

        print(f"Found {len(binary_files)} binary files")

        # Filter files based on kernel/matrix type
        files_to_process = []
        for filepath in sorted(binary_files):
            if should_process_file(filepath):
                files_to_process.append(filepath)

        if not files_to_process:
            print("No files match the kernel/matrix type filters")
            return

        print(f"Processing {len(files_to_process)} files after filtering")

        # Load all results for cross-kernel scaling
        all_results = []
        metadata_list = []
        save_path_prefixes = []

        for filepath in files_to_process:
            print(f"Loading: {filepath}")
            try:
                result = read_binary_file(filepath)
                metadata = read_metadata_csv(filepath)

                all_results.append(result)
                metadata_list.append(metadata)

                # Generate save path prefix
                header = result['header']
                save_path_prefix = os.path.join(args.output_dir,
                                               f"heatmap_{header['kernel_type_name']}_{header['matrix_type_name']}_n{header['matrix_size']}_sample{header['sample_index']}")
                save_path_prefixes.append(save_path_prefix)

                print_tile_statistics_summary(result['tile_stats'], result['header'])

            except Exception as e:
                print(f"Error loading {filepath}: {e}")
                continue

        if not all_results:
            print("No valid results loaded")
            return

        # Create all plots with cross-kernel consistent scaling
        create_all_plots_with_cross_kernel_scaling(all_results, metadata_list,
                                                  colormap=args.colormap, log_scale=args.log_scale,
                                                  save_path_prefixes=save_path_prefixes,
                                                  format_option=SAVE_FORMAT)

if __name__ == "__main__":
    main()